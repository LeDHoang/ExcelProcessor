"""
Simple OCR Example using AWS Bedrock with Bearer Token
This follows the same pattern as testBedrockOcr.py
Exports results to markdown file
"""

import boto3
import json
import os
import base64
from datetime import datetime
from pathlib import Path

# Setup AWS session with bearer token (same pattern as testBedrockOcr.py)
session = boto3.Session(
    aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),
    aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'),
    aws_session_token=os.environ.get('AWS_BEARER_TOKEN_BEDROCK'),
    region_name='ap-southeast-1'
)

bedrock = session.client('bedrock-runtime')

# Claude Sonnet 4.5 model with vision capabilities
model_id = 'global.anthropic.claude-sonnet-4-5-20250929-v1:0'

# Path to image you want to OCR
image_path = 'sheet2.png'

# Check if image exists
if not os.path.exists(image_path):
    print(f"Image not found: {image_path}")
    print("Please update the image_path variable or extract images first:")
    print("  python excelprocessor.py -i Sheet1.xlsx -o output")
    exit(1)

# Read and encode image to base64
with open(image_path, 'rb') as img_file:
    image_data = base64.b64encode(img_file.read()).decode('utf-8')

# Determine image type
if image_path.endswith('.png'):
    media_type = 'image/png'
elif image_path.endswith('.jpg') or image_path.endswith('.jpeg'):
    media_type = 'image/jpeg'
else:
    media_type = 'image/png'

# Prepare request body for Claude with vision
request_body = {
    "anthropic_version": "bedrock-2023-05-31",
    "max_tokens": 4096,
    "messages": [
        {
            "role": "user",
            "content": [
                {
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": media_type,
                        "data": image_data
                    }
                },
                {
                    "type": "text",
                    "text": "Please extract all text from this image. Preserve the structure and formatting."
                }
            ]
        }
    ]
}

print(f"Processing image: {image_path}")
print("Sending request to AWS Bedrock...")
print()

# Call Bedrock with streaming (same as testBedrockOcr.py)
response = bedrock.invoke_model_with_response_stream(
    modelId=model_id,
    body=json.dumps(request_body),
    contentType='application/json'
)

print("=== Extracted Text ===")
print()

# Stream the response and collect text
extracted_text = ""
for event in response['body']:
    chunk = json.loads(event['chunk']['bytes'].decode())
    
    if chunk['type'] == 'content_block_delta':
        if 'text' in chunk['delta']:
            text_chunk = chunk['delta']['text']
            print(text_chunk, end='', flush=True)
            extracted_text += text_chunk
    elif chunk['type'] == 'message_stop':
        break

print()
print()
print("=== OCR Complete ===")

# Generate output filename from input filename
input_filename = Path(image_path).stem  # Gets filename without extension
output_filename = f"{input_filename}_out_ocr_simple.md"

# Create markdown content
markdown_content = f"""# OCR Results

**Source Image:** `{image_path}`  
**Processed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Model:** Claude Sonnet 4.5 (Bedrock)

---

## Extracted Text

{extracted_text}

---

*Generated by AWS Bedrock OCR*
"""

# Save to markdown file
with open(output_filename, 'w', encoding='utf-8') as f:
    f.write(markdown_content)

print()
print(f"âœ“ Markdown saved to: {output_filename}")

